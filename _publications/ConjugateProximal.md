---
title: "Convergence Rates of Proximal Gradient Methods via the Convex Conjugate"
collection: publications
permalink: /publication/ConjugateProximal
excerpt: 'with Javier Pe√±a (Carnegie Mellon University, Tepper School of Business)'
date: 2019-1-17
venue: SIAM Journal on Optimization
paperurl: '[https://epubs.siam.org/doi/abs/10.1137/18M1164329]'

---

We give a novel proof of the $\mathcal{O}(1/k)$ and $\mathcal{O}(1/k^2)$ convergence rates of the proximal gradient and accelerated proximal gradient methods for composite convex minimization. The crux of the new proof is an upper bound constructed via the convex conjugate of the objective function.

Recommended citation: Gutman, D. H., & Pena, J. F. (2019). Convergence rates of proximal gradient methods via the convex conjugate. *SIAM Journal on Optimization*, 29(1), 162-174.

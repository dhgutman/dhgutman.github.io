---
title: "Coordinate Descent Without Coordinates: Tangent Subspace Descent on Riemannian Manifolds"
collection: publications
permalink: /publication/TSD
date: 2022-4-14
venue: Mathematics of Operations Research
paperurl: '[https://doi.org/10.1287/moor.2022.1253]'
---

**2022 INFORMS Optimization Society Young Researcher Prize Winner**

We extend coordinate descent to manifold domains and provide convergence analyses for geodesically convex and nonconvex smooth objective functions. Our key insight is to draw an analogy between coordinate blocks in Euclidean space and tangent subspaces of a manifold. Hence, our method is called tangent subspace descent (TSD). The core principle behind ensuring convergence of TSD is the appropriate choice of subspace at each iteration. To this end, we propose two novel conditions, the (C, r)-norm and C-randomized norm conditions on deterministic and randomized modes of subspace selection, respectively, that promise convergence for smooth functions and that are satisfied in practical contexts. We propose two subspace selection rules, one deterministic and another randomized, of particular practical interest on the Stiefel manifold. Our proof-of-concept numerical experiments on the sparse principal component analysis problem demonstrate TSD’s efficacy.

With Nam Ho-Nguyen (University of Sydney, Discipline of Business Analytics)


